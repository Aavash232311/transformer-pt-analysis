{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f21994c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c886bde",
   "metadata": {},
   "source": [
    "### Loss analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e01518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([8, 6, 4, 0, 4, 4, 8, 2, 0]), tensor([6, 4, 0, 4, 4, 8, 2, 0, 2]))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.mintrans import FibonacciModDataset, MinimalTransformer, evaluate_model, train_model\n",
    "import torch\n",
    "\n",
    "\n",
    "data = FibonacciModDataset(num_samples=10)\n",
    "print(data.__getitem__(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790c1621",
   "metadata": {},
   "source": [
    "### With the default `10` epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e462b066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.0602\n",
      "Epoch 2, Loss: 1.1740\n",
      "Epoch 3, Loss: 0.8985\n",
      "Epoch 4, Loss: 0.7712\n",
      "Epoch 5, Loss: 0.7027\n",
      "Epoch 6, Loss: 0.6506\n",
      "Epoch 7, Loss: 0.6140\n",
      "Epoch 8, Loss: 0.5821\n",
      "Epoch 9, Loss: 0.5587\n",
      "Epoch 10, Loss: 0.5316\n",
      "Accuracy: 80.60%\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10\n",
    "train_ds = FibonacciModDataset(num_samples=5000, mod=vocab_size)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "model = MinimalTransformer(vocab_size=vocab_size)\n",
    "train_model(model, train_loader)\n",
    "evaluate_model(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694928d0",
   "metadata": {},
   "source": [
    "### Epoch increased to `100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "131a23f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5116\n",
      "Epoch 2, Loss: 0.4916\n",
      "Epoch 3, Loss: 0.4788\n",
      "Epoch 4, Loss: 0.4686\n",
      "Epoch 5, Loss: 0.4590\n",
      "Epoch 6, Loss: 0.4480\n",
      "Epoch 7, Loss: 0.4384\n",
      "Epoch 8, Loss: 0.4409\n",
      "Epoch 9, Loss: 0.4311\n",
      "Epoch 10, Loss: 0.4269\n",
      "Epoch 11, Loss: 0.4181\n",
      "Epoch 12, Loss: 0.4223\n",
      "Epoch 13, Loss: 0.4145\n",
      "Epoch 14, Loss: 0.4117\n",
      "Epoch 15, Loss: 0.4083\n",
      "Epoch 16, Loss: 0.3995\n",
      "Epoch 17, Loss: 0.4002\n",
      "Epoch 18, Loss: 0.4028\n",
      "Epoch 19, Loss: 0.3982\n",
      "Epoch 20, Loss: 0.3950\n",
      "Epoch 21, Loss: 0.3922\n",
      "Epoch 22, Loss: 0.3904\n",
      "Epoch 23, Loss: 0.3969\n",
      "Epoch 24, Loss: 0.3898\n",
      "Epoch 25, Loss: 0.3896\n",
      "Epoch 26, Loss: 0.3864\n",
      "Epoch 27, Loss: 0.3873\n",
      "Epoch 28, Loss: 0.3790\n",
      "Epoch 29, Loss: 0.3807\n",
      "Epoch 30, Loss: 0.3861\n",
      "Epoch 31, Loss: 0.3761\n",
      "Epoch 32, Loss: 0.3728\n",
      "Epoch 33, Loss: 0.3689\n",
      "Epoch 34, Loss: 0.3861\n",
      "Epoch 35, Loss: 0.3781\n",
      "Epoch 36, Loss: 0.3716\n",
      "Epoch 37, Loss: 0.3714\n",
      "Epoch 38, Loss: 0.3650\n",
      "Epoch 39, Loss: 0.3740\n",
      "Epoch 40, Loss: 0.3652\n",
      "Accuracy: 87.31%\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, epochs=40)\n",
    "evaluate_model(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aecadb",
   "metadata": {},
   "source": [
    "We have `~5.42%` accuracy increase with `10` times more epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce2a1f",
   "metadata": {},
   "source": [
    "### Increasing the batch size from `32` to `64` with epoch as `10`\n",
    "\n",
    "Accuracy goes from ~75-80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14714fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3182\n",
      "Epoch 2, Loss: 1.8917\n",
      "Epoch 3, Loss: 1.3045\n",
      "Epoch 4, Loss: 1.0016\n",
      "Epoch 5, Loss: 0.8647\n",
      "Epoch 6, Loss: 0.7786\n",
      "Epoch 7, Loss: 0.7189\n",
      "Epoch 8, Loss: 0.6718\n",
      "Epoch 9, Loss: 0.6379\n",
      "Epoch 10, Loss: 0.6109\n",
      "Accuracy: 80.25%\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10 # that is mod in our case\n",
    "train_ds = FibonacciModDataset(num_samples=5000, mod=vocab_size)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "model = MinimalTransformer(vocab_size=vocab_size)\n",
    "train_model(model, train_loader)\n",
    "evaluate_model(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3d209",
   "metadata": {},
   "source": [
    "### Switching back to default `batch_size` of `32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "706dbe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2086\n",
      "Epoch 2, Loss: 1.6410\n",
      "Epoch 3, Loss: 1.3067\n",
      "Epoch 4, Loss: 1.0093\n",
      "Epoch 5, Loss: 0.8591\n",
      "Epoch 6, Loss: 0.7811\n",
      "Epoch 7, Loss: 0.7294\n",
      "Epoch 8, Loss: 0.6971\n",
      "Epoch 9, Loss: 0.6655\n",
      "Epoch 10, Loss: 0.6406\n",
      "Accuracy: 79.93%\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10 # that is mod in our case\n",
    "train_ds = FibonacciModDataset(num_samples=5000, mod=vocab_size)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "model = MinimalTransformer(vocab_size=vocab_size)\n",
    "train_model(model, train_loader)\n",
    "evaluate_model(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7457b8a2",
   "metadata": {},
   "source": [
    "## Splitted dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91f4275f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2762\n",
      "Epoch 2, Loss: 1.7730\n",
      "Epoch 3, Loss: 1.3019\n",
      "Epoch 4, Loss: 0.9687\n",
      "Epoch 5, Loss: 0.8391\n",
      "Epoch 6, Loss: 0.7652\n",
      "Epoch 7, Loss: 0.7061\n",
      "Epoch 8, Loss: 0.6672\n",
      "Epoch 9, Loss: 0.6377\n",
      "Epoch 10, Loss: 0.6122\n",
      "Accuracy: 80.67%\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "vocab_size = 10\n",
    "generated_ds = FibonacciModDataset(num_samples=5000, mod=vocab_size)\n",
    "train_size = int(0.8 * len(generated_ds)) # 80% to train\n",
    "test_size = len(generated_ds) - train_size # rest of the size\n",
    "\n",
    "train_ds, test_ds = random_split(generated_ds, [train_size, test_size]) # randomly splits our dataset\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "model = MinimalTransformer(vocab_size=vocab_size)\n",
    "train_model(model, train_loader)\n",
    "\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c598634",
   "metadata": {},
   "source": [
    "## Splitted dataset and increase in number of epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30c5297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5923\n",
      "Epoch 2, Loss: 0.5775\n",
      "Epoch 3, Loss: 0.5640\n",
      "Epoch 4, Loss: 0.5523\n",
      "Epoch 5, Loss: 0.5457\n",
      "Epoch 6, Loss: 0.5290\n",
      "Epoch 7, Loss: 0.5207\n",
      "Epoch 8, Loss: 0.5153\n",
      "Epoch 9, Loss: 0.5033\n",
      "Epoch 10, Loss: 0.4943\n",
      "Epoch 11, Loss: 0.4923\n",
      "Epoch 12, Loss: 0.4793\n",
      "Epoch 13, Loss: 0.4771\n",
      "Epoch 14, Loss: 0.4728\n",
      "Epoch 15, Loss: 0.4720\n",
      "Epoch 16, Loss: 0.4653\n",
      "Epoch 17, Loss: 0.4607\n",
      "Epoch 18, Loss: 0.4620\n",
      "Epoch 19, Loss: 0.4616\n",
      "Epoch 20, Loss: 0.4479\n",
      "Epoch 21, Loss: 0.4470\n",
      "Epoch 22, Loss: 0.4413\n",
      "Epoch 23, Loss: 0.4384\n",
      "Epoch 24, Loss: 0.4449\n",
      "Epoch 25, Loss: 0.4363\n",
      "Epoch 26, Loss: 0.4322\n",
      "Epoch 27, Loss: 0.4319\n",
      "Epoch 28, Loss: 0.4230\n",
      "Epoch 29, Loss: 0.4251\n",
      "Epoch 30, Loss: 0.4327\n",
      "Epoch 31, Loss: 0.4233\n",
      "Epoch 32, Loss: 0.4158\n",
      "Epoch 33, Loss: 0.4159\n",
      "Epoch 34, Loss: 0.4127\n",
      "Epoch 35, Loss: 0.4128\n",
      "Epoch 36, Loss: 0.4181\n",
      "Epoch 37, Loss: 0.4117\n",
      "Epoch 38, Loss: 0.4078\n",
      "Epoch 39, Loss: 0.4115\n",
      "Epoch 40, Loss: 0.4118\n",
      "Epoch 41, Loss: 0.4033\n",
      "Epoch 42, Loss: 0.4010\n",
      "Epoch 43, Loss: 0.4047\n",
      "Epoch 44, Loss: 0.4060\n",
      "Epoch 45, Loss: 0.4175\n",
      "Epoch 46, Loss: 0.3992\n",
      "Epoch 47, Loss: 0.4024\n",
      "Epoch 48, Loss: 0.4007\n",
      "Epoch 49, Loss: 0.3927\n",
      "Epoch 50, Loss: 0.3948\n",
      "Epoch 51, Loss: 0.4190\n",
      "Epoch 52, Loss: 0.3924\n",
      "Epoch 53, Loss: 0.3962\n",
      "Epoch 54, Loss: 0.3934\n",
      "Epoch 55, Loss: 0.3973\n",
      "Epoch 56, Loss: 0.3978\n",
      "Epoch 57, Loss: 0.3902\n",
      "Epoch 58, Loss: 0.3891\n",
      "Epoch 59, Loss: 0.3981\n",
      "Epoch 60, Loss: 0.4253\n",
      "Epoch 61, Loss: 0.3951\n",
      "Epoch 62, Loss: 0.3886\n",
      "Epoch 63, Loss: 0.3907\n",
      "Epoch 64, Loss: 0.3871\n",
      "Epoch 65, Loss: 0.3863\n",
      "Epoch 66, Loss: 0.4032\n",
      "Epoch 67, Loss: 0.3908\n",
      "Epoch 68, Loss: 0.3855\n",
      "Epoch 69, Loss: 0.3811\n",
      "Epoch 70, Loss: 0.3867\n",
      "Epoch 71, Loss: 0.3843\n",
      "Epoch 72, Loss: 0.3865\n",
      "Epoch 73, Loss: 0.3908\n",
      "Epoch 74, Loss: 0.3936\n",
      "Epoch 75, Loss: 0.3808\n",
      "Epoch 76, Loss: 0.3948\n",
      "Epoch 77, Loss: 0.3838\n",
      "Epoch 78, Loss: 0.3784\n",
      "Epoch 79, Loss: 0.3770\n",
      "Epoch 80, Loss: 0.3802\n",
      "Epoch 81, Loss: 0.3817\n",
      "Epoch 82, Loss: 0.3769\n",
      "Epoch 83, Loss: 0.3757\n",
      "Epoch 84, Loss: 0.3992\n",
      "Epoch 85, Loss: 0.3923\n",
      "Epoch 86, Loss: 0.3931\n",
      "Epoch 87, Loss: 0.3745\n",
      "Epoch 88, Loss: 0.3764\n",
      "Epoch 89, Loss: 0.3783\n",
      "Epoch 90, Loss: 0.3904\n",
      "Epoch 91, Loss: 0.3913\n",
      "Epoch 92, Loss: 0.3774\n",
      "Epoch 93, Loss: 0.3704\n",
      "Epoch 94, Loss: 0.3710\n",
      "Epoch 95, Loss: 0.3932\n",
      "Epoch 96, Loss: 0.3828\n",
      "Epoch 97, Loss: 0.3808\n",
      "Epoch 98, Loss: 0.3749\n",
      "Epoch 99, Loss: 0.3689\n",
      "Epoch 100, Loss: 0.3944\n",
      "Epoch 101, Loss: 0.3823\n",
      "Epoch 102, Loss: 0.3731\n",
      "Epoch 103, Loss: 0.3761\n",
      "Epoch 104, Loss: 0.3706\n",
      "Epoch 105, Loss: 0.3774\n",
      "Epoch 106, Loss: 0.3749\n",
      "Epoch 107, Loss: 0.3698\n",
      "Epoch 108, Loss: 0.4222\n",
      "Epoch 109, Loss: 0.3747\n",
      "Epoch 110, Loss: 0.3705\n",
      "Epoch 111, Loss: 0.3930\n",
      "Epoch 112, Loss: 0.3753\n",
      "Epoch 113, Loss: 0.3656\n",
      "Epoch 114, Loss: 0.3652\n",
      "Epoch 115, Loss: 0.3730\n",
      "Epoch 116, Loss: 0.3819\n",
      "Epoch 117, Loss: 0.3901\n",
      "Epoch 118, Loss: 0.3829\n",
      "Epoch 119, Loss: 0.3682\n",
      "Epoch 120, Loss: 0.3658\n",
      "Epoch 121, Loss: 0.3632\n",
      "Epoch 122, Loss: 0.3627\n",
      "Epoch 123, Loss: 0.3669\n",
      "Epoch 124, Loss: 0.3905\n",
      "Epoch 125, Loss: 0.3657\n",
      "Epoch 126, Loss: 0.3727\n",
      "Epoch 127, Loss: 0.4141\n",
      "Epoch 128, Loss: 0.3716\n",
      "Epoch 129, Loss: 0.3629\n",
      "Epoch 130, Loss: 0.3641\n",
      "Epoch 131, Loss: 0.3638\n",
      "Epoch 132, Loss: 0.3626\n",
      "Epoch 133, Loss: 0.3683\n",
      "Epoch 134, Loss: 0.4090\n",
      "Epoch 135, Loss: 0.3688\n",
      "Epoch 136, Loss: 0.3724\n",
      "Epoch 137, Loss: 0.3700\n",
      "Epoch 138, Loss: 0.3639\n",
      "Epoch 139, Loss: 0.3620\n",
      "Epoch 140, Loss: 0.3615\n",
      "Epoch 141, Loss: 0.3685\n",
      "Epoch 142, Loss: 0.3635\n",
      "Epoch 143, Loss: 0.3608\n",
      "Epoch 144, Loss: 0.3771\n",
      "Epoch 145, Loss: 0.3770\n",
      "Epoch 146, Loss: 0.3634\n",
      "Epoch 147, Loss: 0.3638\n",
      "Epoch 148, Loss: 0.3793\n",
      "Epoch 149, Loss: 0.3735\n",
      "Epoch 150, Loss: 0.3667\n",
      "Mean accuracy across epochs (Training): 86.2185%\n",
      "Accuracy: 87.34%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "def train_model(model, dataloader, epochs=10, lr=1e-3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "\n",
    "    accuracy_per_e = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pred = logits.argmax(dim=-1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.numel()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        acc = correct / total\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy_per_e.append(acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(f\"Mean accuracy across epochs (Training): {sum(accuracy_per_e) / len(accuracy_per_e):.4%}\")\n",
    "\n",
    "train_model(model, train_loader, epochs=150)\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca2c2d",
   "metadata": {},
   "source": [
    "## Hyperparamater adjustment\n",
    "\n",
    "Adjusting hypermaters:- (model no longer learns)\n",
    "\n",
    "\n",
    "`batch_size`: `256`\n",
    "\n",
    "`epoch`: `20`\n",
    "\n",
    "`LR`: `10^-3`\n",
    "\n",
    "`d_model`: `32`\n",
    "\n",
    "`n_head`: `8`\n",
    "\n",
    "`n_layer`: `6` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c380c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3684\n",
      "Epoch 2, Loss: 0.3575\n",
      "Epoch 3, Loss: 0.3562\n",
      "Epoch 4, Loss: 0.3797\n",
      "Epoch 5, Loss: 0.3784\n",
      "Epoch 6, Loss: 0.3565\n",
      "Epoch 7, Loss: 0.3588\n",
      "Epoch 8, Loss: 0.3552\n",
      "Epoch 9, Loss: 0.3580\n",
      "Epoch 10, Loss: 0.3598\n",
      "Epoch 11, Loss: 0.4149\n",
      "Epoch 12, Loss: 0.3637\n",
      "Epoch 13, Loss: 0.3575\n",
      "Epoch 14, Loss: 0.3587\n",
      "Epoch 15, Loss: 0.3579\n",
      "Epoch 16, Loss: 0.3645\n",
      "Epoch 17, Loss: 0.3702\n",
      "Epoch 18, Loss: 0.3878\n",
      "Epoch 19, Loss: 0.3620\n",
      "Epoch 20, Loss: 0.3567\n",
      "Accuracy: 87.48%\n"
     ]
    }
   ],
   "source": [
    "from src.mintrans import *\n",
    "\n",
    "train_model(model, train_loader, epochs=20)\n",
    "evaluate_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
